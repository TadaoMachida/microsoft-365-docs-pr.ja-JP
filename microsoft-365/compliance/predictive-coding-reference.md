---
title: プレディクティブ コーディングの参照
f1.keywords:
- NOCSH
ms.author: v-tophillips
author: v-tophillips
ms.reviewer: jefwan
manager: laurawi
audience: Admin
ms.topic: article
ms.service: O365-seccomp
ms.localizationpriority: medium
search.appverid:
- MET150
ms.collection: M365-security-compliance
description: ''
ms.openlocfilehash: da8ea6f996735edb91b7191bbcf90df02e134428
ms.sourcegitcommit: e50c13d9be3ed05ecb156d497551acf2c9da9015
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 04/27/2022
ms.locfileid: "65091481"
---
# <a name="predictive-coding-reference-preview"></a>予測コーディングリファレンス (プレビュー)

[!include[Purview banner](../includes/purview-rebrand-banner.md)]

この記事では、Microsoft Purview 電子情報開示 (プレミアム) の予測コーディング ツールの主要な概念とメトリックについて説明します。 記事のセクションはアルファベット順に一覧表示されます。

## <a name="confidence-level"></a>信頼度

信頼度レベルは、予測コーディング モデルを作成するときの高度な設定です。 モデルのパフォーマンス メトリック (リッチ度、精度、再現率など) が、モデルがレビュー セット内の項目に割り当てる予測スコアの真の値を表す指定された範囲内 (モデルに定義された誤差の余白を決定します) 内に収まることを定義します。 信頼度レベルと誤差の余白の値は、コントロール セットに含まれる項目の数を決定するのにも役立ちます。 信頼レベルの既定値は 0.95 または 95% です。

## <a name="control-set"></a>コントロール セット

コントロール セットは、予測コーディング モデルのトレーニング プロセス中に使用されます。 コントロール セットは、トレーニング ラウンド中に実行するラベル付けを使用して、モデルがアイテムに割り当てる予測スコアを評価することです。 コントロール セットのサイズは、レビュー セット内の項目の数と、モデルの作成時に設定されるエラー値の信頼レベルと余白に基づきます。 コントロール セット内の項目は変更されず、ユーザーが識別できません。 コントロール セット内の項目の合計数は、トレーニング ラウンドのポップアップ ページに表示されます。

## <a name="control-set-confusion-matrix"></a>コントロール セットの混同行列

トレーニング ラウンドを完了すると、モデルはトレーニング ラウンド中にラベル付けしたコントロール セット内の 10 項目に予測スコアを割り当てます。 モデルは、トレーニング ラウンド中にアイテムに割り当てた実際のラベルと、これらの 10 項目の予測スコアを比較します。 この比較に基づいて、モデルは、モデルの予測パフォーマンスを評価するために次の分類を識別します。

<br>

****

|Label|モデルはアイテムが関連すると予測します|モデルはアイテムが関連しないと予測します|
|---|---|---|
|**レビュー担当者ラベルアイテムを関連項目として表示する**|真陽性|誤検知|
|**レビュー担当者ラベルアイテムが関連しない**|False negative|真の負の値|
|

これらの比較に基づいて、モデルは F スコア、有効桁数、およびリコールメトリックの値と、それぞれの誤差の余白を派生させます。 マトリックスの各混同型の数は、トレーニング ラウンドのポップアップ ページに表示されます。

## <a name="f-score"></a>F スコア

F スコアは、精度メトリックと再現メトリックのスコアの加重平均です。  このメトリックのスコアの範囲は **0** から **1 です**。 **1** に近いスコアは、モデルが関連する項目をより正確に検出することを示します。 F スコア メトリックは、モデル ダッシュボードと各トレーニング ラウンドのポップアップ ページに表示されます。

## <a name="margin-of-error"></a>エラーの余白

エラーの余白は、予測コーディング モードを作成するときの高度な設定です。 コントロール セット内の項目のランダム サンプリングから派生したパフォーマンス メトリック (リッチ度、精度、再現率など) のエラーの度合いを指定します。 誤差の余白を小さくするには、モデルのパフォーマンス メトリックが小さい範囲内に収まるように、より大きなコントロール セットが必要です。 誤差と信頼度レベルの余白の値は、コントロール セットに含まれる項目の数を決定するのにも役立ちます。 誤差の余白の既定値は 0.05 または 5% です。

## <a name="model-stability"></a>モデルの安定性

モデルの安定性は、レビュー セット内のドキュメントが関連しているかどうかを正確に予測するモデルの機能を示します。 モデルが不安定な場合は、モデルの安定性を含めるために、より多くのトレーニング ラウンドを実行する必要がある場合があります。 モデルが安定している場合は、トレーニング ラウンドを実行する必要がなくなりました。 モデル ダッシュボードは、モデルの安定性の現在の状態を示します。 モデルが安定している場合、パフォーマンス メトリックは、信頼レベルと誤差の余白の設定と一致するレベルに達しました。

## <a name="overturn-rate"></a>転覆率

転覆率は、トレーニング ラウンド間で予測スコアが変更されたレビュー セット内のアイテムの割合です。 転覆率が 5% 未満の場合、モデルは安定していると見なされます。 転覆率メトリックは、モデル ダッシュボードと各トレーニング ラウンドのポップアップ ページに表示されます。 最初のトレーニング ラウンドの転覆率は 0 です。これは、覆す前の予測スコアがないためです。

## <a name="precision"></a>精度

精度メトリックは、モデルが予測した項目間で実際に関連する項目の割合を測定します。 つまり、コントロール内のアイテムは、レビュー担当者が関連するラベルを設定し、モデルによって関連性があると予測します。 このメトリックのスコアの範囲は **0** から **1 です**。 **スコアが 1** に近い場合、モデルで識別される非関連項目の数が少なくなることが示されます。 精度メトリックは、モデル ダッシュボードと各トレーニング ラウンドのポップアップ ページに表示されます。

## <a name="prediction-score"></a>予測スコア

これは、モデルがレビュー セット内の各ドキュメントに割り当てるスコアです。 スコアは、トレーニング ラウンドからのモデルの学習と比較して、ドキュメントの関連性に基づいています。 一般に、予測スコアが **0** ~ **0.5** の項目は関連しないと見なされ、予測スコアが **0.5** から **1** の項目は関連性が高いと見なされます。 予測スコアは、ドキュメント メタデータ フィールドに含まれています。 予測フィルターを使用して、指定した予測範囲内にあるレビュー セット内のアイテムを表示できます。

## <a name="recall"></a>リコール

リコールメトリックは、モデルが実際に関連するアイテム間で関連していたと予測されたアイテムの割合を測定します。 つまり、予測されたモデルが関連するコントロール セット内のアイテムも、校閲者によって関連するラベルが付けられます。 このメトリックのスコアの範囲は **0** から **1 です**。 **1** に近いスコアは、モデルが関連項目の大部分を識別することを示します。 再現率メトリックは、モデル ダッシュボードと各トレーニング ラウンドのポップアップ ページに表示されます。

## <a name="review-set"></a>レビュー セット

レビュー セットは、予測コーディング モデルのスコープを提供します。 レビュー セットの新しいモデルを作成すると、コントロール セットとトレーニング セットの項目がレビュー セットから選択されます。 モデルが予測スコアを割り当てると、レビューの項目にそれらのスコアが割り当てられます。 予測コーディング モデルを作成する前に、すべての項目をレビュー セットに追加する必要があります。 モデルの作成後に項目を追加した場合、それらの項目には予測スコアは割り当てられません。

## <a name="richness"></a>豊か さ

リッチネス メトリックは、モデルが関連として予測するレビュー セット アイテムの割合を測定します。 このメトリックのスコアの範囲は **0** から **1 です**。 リッチネス メトリックは、モデル ダッシュボードに表示されます。

## <a name="sampled-items"></a>サンプリングされたアイテム

*サンプル項目* という用語は、予測コーディング モデルを作成するときに選択され、コントロール セットに関連付けられているレビュー セット内の項目のランダムなサンプル (テキストを含む) への参照です。 トレーニング ラウンドごとに、項目のランダムなサンプルも選択されます。 モデルのコントロール セットに対して選択された項目は、その同じモデルのトレーニング セットには含まれません。 逆の場合も同様です。トレーニング セット項目はコントロール セットに含まれません。

## <a name="training-set"></a>トレーニング セット

モデルは、レビュー セットから項目をランダムに選択し、トレーニング セットに追加します。 トレーニング ラウンド中に、トレーニング セットのアイテム (コントロール セットの項目に加えて) が表示され、それぞれを "関連する" または "関連性のない" ラベルを付けることができます。 このラベル付けまたは "トレーニング" プロセスは、モデルがレビューのどの項目が関連しているか、関連しないかを予測する方法を学習するのに役立ちます。 トレーニング ラウンドを実行するたびに、モデルはレビューからより多くの項目を選択し、そのトレーニング ラウンドのトレーニング セットに追加します。 コントロール セットの項目は、トレーニング セットでは選択されません。
